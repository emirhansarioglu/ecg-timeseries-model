{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "509777cc",
   "metadata": {},
   "source": [
    "# Model DL: Wavelet Transform + CNN\n",
    "Hypothesis: Wavelet transform can improve anomaly detection in ECG signals. So it can also improve classification of them.\n",
    "But wavelets capture temporal characteristics that correlate with signal length, and we already established that different classes have different lengths. \n",
    "Also we should keep some type of short term locality to keep the local features that wavelets are good at capturing. So go easy on the pooling layers and use multiple kernel sizes. \n",
    "\n",
    "Consider: adaptive pooling or attention mechanisms to better handle variable-length signals.\n",
    "--> for that case move transform inside the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "train_df = pd.read_pickle(\"train_df.pkl\")\n",
    "val_df = pd.read_pickle(\"val_df.pkl\")\n",
    "\n",
    "INPUT_LENGTH = 9000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# lengths after transformations!!!\n",
    "expected_lengths = {\n",
    "    \"wavelet\": 143,  # Only using approximate coefficients, reduces length significantly TODO: function that calculates this with dummy input\n",
    "    \"fourier\": INPUT_LENGTH,\n",
    "    None: INPUT_LENGTH,  #\n",
    "}\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)  # Python random\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_seed(42)\n",
    "print(\"Seed set for reproducibility.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172646b3",
   "metadata": {},
   "source": [
    "### Wavelet Transform\n",
    "Following cell is to illustrate the wavelet transform and its effect on the signal characteristics. It could also be useful when selecting the mother wavelet and level of decomposition.\n",
    "\n",
    "**It is not relevant to the model itself. You can skip just skip it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e5334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = np.linspace(0, 1, 256)\n",
    "sample_signal = train_df.iloc[0][\"signal\"]  \n",
    "sample_signal = np.array(sample_signal, dtype=np.float32)\n",
    "\n",
    "\n",
    "wavelet = pywt.Wavelet(\"db2\")\n",
    "levels = 6\n",
    "\n",
    "coeffs = pywt.wavedec(sample_signal, wavelet, level=levels)\n",
    "\n",
    "print(f\"Number of coefficient arrays: {len(coeffs)}\")\n",
    "print(f\"Approximation coefficients shape: {coeffs[0].shape}\")\n",
    "for i in range(1, len(coeffs)):\n",
    "    print(f\"Detail level {i} coefficients shape: {coeffs[i].shape}\")\n",
    "\n",
    "# Plot the original signal\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(levels + 2, 1, 1)\n",
    "plt.plot(sample_signal, \"b-\", linewidth=1)\n",
    "plt.title(\"Original Signal\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "\n",
    "\n",
    "approx_only = pywt.waverec(\n",
    "    [coeffs[0]] + [np.zeros_like(c) for c in coeffs[1:]], wavelet\n",
    ")\n",
    "plt.subplot(levels + 2, 1, 2)\n",
    "plt.plot(approx_only, \"r-\", linewidth=1)\n",
    "plt.plot(sample_signal, \"b-\", alpha=0.3, linewidth=0.5)\n",
    "plt.title(\"Approximation Only (Lowest Frequencies)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "\n",
    "# ---------------- Progressive Reconstruction ----------------\n",
    "for level in range(1, levels + 1):\n",
    "\n",
    "    partial_coeffs = [coeffs[0]]  \n",
    "\n",
    "    for i in range(1, level + 1):\n",
    "        partial_coeffs.append(coeffs[i])  # add details up to current level\n",
    "\n",
    "    \n",
    "    for i in range(level + 1, levels + 1):\n",
    "        partial_coeffs.append(np.zeros_like(coeffs[i])) # add zeros for remaining detail levels\n",
    "\n",
    "    reconstructed = pywt.waverec(partial_coeffs, wavelet)\n",
    "\n",
    "    plt.subplot(levels + 2, 1, level + 2)\n",
    "    plt.plot(reconstructed, \"g-\", linewidth=1, label=f\"Approx + Details 1-{level}\")\n",
    "    plt.plot(sample_signal, \"b-\", alpha=0.3, linewidth=0.5, label=\"Original\")\n",
    "    plt.title(f\"Reconstruction: Approximation + Detail Levels 1-{level}\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    if level == levels:\n",
    "        plt.xlabel(\"Samples\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --------------------- Detail Levels Only ---------------------\n",
    "plt.figure(figsize=(15, 8))\n",
    "for level in range(1, levels + 1):\n",
    "    detail_coeffs = [np.zeros_like(coeffs[0])]  # Zero approximation\n",
    "\n",
    "    for i in range(1, levels + 1):\n",
    "        if i == level:\n",
    "            detail_coeffs.append(coeffs[i])\n",
    "        else:\n",
    "            detail_coeffs.append(np.zeros_like(coeffs[i]))\n",
    "\n",
    "    detail_only = pywt.waverec(detail_coeffs, wavelet)\n",
    "\n",
    "    plt.subplot(levels, 1, level)\n",
    "    plt.plot(detail_only, \"r-\", linewidth=1)\n",
    "    plt.title(f\"Detail Level {level} Only\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    if level == levels:\n",
    "        plt.xlabel(\"Samples\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --------------- Progressive Reconstruction Error ---------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "errors = []\n",
    "level_names = [\"Approximation Only\"]\n",
    "\n",
    "# Error for approximation only\n",
    "approx_only = pywt.waverec(\n",
    "    [coeffs[0]] + [np.zeros_like(c) for c in coeffs[1:]], wavelet\n",
    ")\n",
    "error = np.mean((sample_signal - approx_only) ** 2)\n",
    "errors.append(error)\n",
    "\n",
    "# Error for progressive reconstruction\n",
    "for level in range(1, levels + 1):\n",
    "    partial_coeffs = [coeffs[0]]\n",
    "    for i in range(1, level + 1):\n",
    "        partial_coeffs.append(coeffs[i])\n",
    "    for i in range(level + 1, levels + 1):\n",
    "        partial_coeffs.append(np.zeros_like(coeffs[i]))\n",
    "\n",
    "    reconstructed = pywt.waverec(partial_coeffs, wavelet)\n",
    "    error = np.mean((sample_signal - reconstructed) ** 2)\n",
    "    errors.append(error)\n",
    "    level_names.append(f\"+ Detail {level}\")\n",
    "\n",
    "plt.semilogy(errors, \"bo-\", linewidth=2, markersize=8)\n",
    "plt.xticks(range(len(level_names)), level_names, rotation=45)\n",
    "plt.ylabel(\"Mean Squared Error (log scale)\")\n",
    "plt.title(\"Reconstruction Error vs. Number of Detail Levels\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final reconstruction error: {errors[-1]:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ed868",
   "metadata": {},
   "source": [
    "# 1.3 Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation functions\n",
    "import scipy.signal\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# wrapping them in nn.Module should not introduce huge overhead\n",
    "\n",
    "\n",
    "def time_shift(signal, shift_range=(-100, 100)):\n",
    "    shift = np.roll(signal, shift=random.randint(shift_range[0], shift_range[1]))\n",
    "    return shift    \n",
    "\n",
    "\n",
    "def add_noise(signal, noise_level=0.1):\n",
    "    noise = np.random.normal(0, noise_level, signal.shape)\n",
    "    return signal + noise\n",
    "\n",
    "\n",
    "def time_warp(signal, warp_factor=0.1):\n",
    "    return scipy.signal.resample(signal,int(len(signal) * (1 + np.random.uniform(-warp_factor, warp_factor))))\n",
    "\n",
    "\n",
    "def amplitude_scaling(signal, scale_range=(0.8, 1.2)):\n",
    "    scale = random.uniform(scale_range[0], scale_range[1])\n",
    "    return signal * scale\n",
    "\n",
    "\n",
    "def pad_or_trim(signal, target_length=INPUT_LENGTH):\n",
    "    current_length = len(signal)\n",
    "\n",
    "    if current_length < target_length:\n",
    "        # Pad with zeros at the end\n",
    "        padding = target_length - current_length\n",
    "        signal = np.pad(signal, (0, padding), \"constant\")\n",
    "    elif current_length > target_length:\n",
    "        # Trim from center\n",
    "        start = (current_length - target_length) // 2\n",
    "        signal = signal[start : start + target_length]\n",
    "\n",
    "    return signal\n",
    "\n",
    "\n",
    "def pad_and_augment(signal, augmentation = \"all\"):\n",
    "    if (augmentation == \"all\" or augmentation == \"warp_only\") and random.random() < 0.5:\n",
    "        signal = time_warp(signal)\n",
    "\n",
    "    signal = pad_or_trim(signal, INPUT_LENGTH)  # Ensure the signal is of the expected length\n",
    "\n",
    "    for aug in [add_noise, time_shift, amplitude_scaling]:\n",
    "        if augmentation == \"all\" or augmentation != \"shift_only\":\n",
    "            if random.random() < 0.5 and aug != time_warp:\n",
    "                signal = aug(signal)\n",
    "    return signal\n",
    "\n",
    "# generic dataset with adjustable preprocessing (data augmentation + wavelet/fourier transform)\n",
    "def wavelet_transform(signal, wavelet=\"db2\", levels=6):\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=levels)\n",
    "    # Return only the approximation coefficients\n",
    "    return coeffs[0]\n",
    "\n",
    "def fourier_transform(signal):\n",
    "    # Apply Fourier Transform and return the absolute values of the coefficients\n",
    "    coeffs = np.fft.fft(signal)\n",
    "    return np.abs(coeffs)\n",
    "\n",
    "\n",
    "class ECGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, signal_transform = None, augmentation=None):\n",
    "        self.df = df\n",
    "        self.signal_transform = signal_transform\n",
    "        self.augmentation = augmentation\n",
    "        self.target_length = (\n",
    "            expected_lengths[self.signal_transform]\n",
    "            if self.signal_transform\n",
    "            else INPUT_LENGTH\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal = self.df.iloc[idx]['signal']\n",
    "        signal = np.array(signal, dtype=np.float32)\n",
    "        label = int(self.df.iloc[idx]['label'])\n",
    "\n",
    "        # keep it simple: time domain augmentation only\n",
    "        signal = pad_and_augment(signal, self.augmentation) # has padding in it. the order of augmentations should be important (wrapping changes the shape but noise and scaling before padding makes it easier to distinguish the signal length)\n",
    "       \n",
    "\n",
    "        if self.signal_transform == \"wavelet\":\n",
    "            signal = wavelet_transform(signal)\n",
    "        elif self.signal_transform == \"fourier\":\n",
    "            signal = fourier_transform(signal)\n",
    "\n",
    "        signal = torch.tensor(signal, dtype=torch.float32) \n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return signal, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d875f",
   "metadata": {},
   "source": [
    "Adding noise after padding otherwise the model can cheat by learning where the real data ends, and use only that to discriminate between classes (different classes in training data have different mean lengths).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7450add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = ECGDataset(train_df, signal_transform=\"wavelet\", augmentation=None)\n",
    "val_dataset = ECGDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    generator=torch.Generator().manual_seed(42),\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ec4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_signal, sample_label = next(iter(train_loader))\n",
    "print(f\"Sample signal shape: {sample_signal.shape}\")\n",
    "print(f\"Sample label shape: {sample_label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a450806",
   "metadata": {},
   "source": [
    "##### A Question:\n",
    "\n",
    "Conv is defined as Conv(x, k) ≡ IFFT(FFT(x) * FFT(k))  \n",
    "But PyTorch does not compute the convolution this way.\n",
    "So are there still opportunities for fusing etc. when calling FFT+Conv one after the other?\n",
    "\n",
    "x is NxN, k is KxK, and N >> K.\n",
    "\n",
    "Conv(FFT(x), k) = IFFT(FFT(FFT(x)) ⋅ FFT(k)) = N ⋅(circular_conv(reverse(x),k))\n",
    "\n",
    "##### Complexities (Conv only)\n",
    "\n",
    "normal spacial conv(x,k) -> O(N^2 * K^2)\n",
    "\n",
    "FFTConv(x,k) -> O(N^2 * log(N))\n",
    "\n",
    "Overlap and Add Conv [Highlander, 2016](https://arxiv.org/pdf/1601.06815) -> O(N^2 * log(K))\n",
    "\n",
    "\n",
    "\n",
    "##### What I found\n",
    "\n",
    "It is not worth it when K is small like typical CNN kernels. Could be considered for large kernels like 10x10 or larger.\n",
    "[some benchmark](https://github.com/fkodom/fft-conv-pytorch?utm_source=chatgpt.com), [its blog post](https://fkodom.substack.com/p/fourier-convolutions-in-pytorch)\n",
    "\n",
    "Paper implementing OaAConv variant-SplitConv in Verilog!: [paper](https://arxiv.org/pdf/2003.12621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7daa54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def he_init_weights(m):\n",
    "    \"\"\"He initialization for weights\"\"\"\n",
    "    if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class SimpleCNNwithoutClassifier(nn.Module):\n",
    "    # remove classifier layer, use as feature extractor\n",
    "    def __init__(self, input_channels=1, feature_size=50, input_length=INPUT_LENGTH):\n",
    "        super(SimpleCNNwithoutClassifier, self).__init__()\n",
    "        self.input_length = input_length\n",
    "        self.input_channels = input_channels\n",
    "        self.feature_size = feature_size\n",
    "        self.conv1 = nn.Conv1d(input_channels, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        conv_output_size = 32 * (input_length // 4)\n",
    "\n",
    "        self.fc1 = nn.Linear(conv_output_size, feature_size)\n",
    "        self.apply(he_init_weights)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels=1,\n",
    "        num_classes=5,\n",
    "        feature_size=128, # hidden_size\n",
    "        input_length=INPUT_LENGTH,\n",
    "    ):\n",
    "\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.cnn_feature_extractor = SimpleCNNwithoutClassifier(\n",
    "            input_channels=input_channels, feature_size=feature_size, input_length=input_length\n",
    "        )\n",
    "        self.fc_classifier = nn.Linear(feature_size, self.num_classes)\n",
    "        self.apply(he_init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_classifier(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Make predictions using the trained CNN\"\"\"\n",
    "        with torch.no_grad():\n",
    "            x = self.forward(x)\n",
    "            _, predicted = torch.max(x, 1)\n",
    "        return predicted\n",
    "\n",
    "class CNNwithSVM(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels=1,\n",
    "        feature_size=50,\n",
    "        num_classes=5,   # not necessary, adding this so I have a consistent interface. For a larger project it would be better to have a dedicated model selector function.\n",
    "        input_length=INPUT_LENGTH,\n",
    "    ):\n",
    "        super(CNNwithSVM, self).__init__()\n",
    "        self.cnn_feature_extractor = SimpleCNNwithoutClassifier(\n",
    "            input_channels=input_channels,\n",
    "            feature_size=feature_size,\n",
    "            input_length=input_length,\n",
    "        )\n",
    "        self.svm = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", random_state=42)\n",
    "        self.is_svm_trained = False\n",
    "        self.apply(he_init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Make predictions using the trained SVM\"\"\"\n",
    "        if not self.is_svm_trained:\n",
    "            raise ValueError(\"SVM has not been trained yet!\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = self.forward(x)\n",
    "            features_np = features.cpu().numpy()\n",
    "            predictions = self.svm.predict(features_np)\n",
    "        return torch.tensor(predictions, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c242c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10, lr=0.001):\n",
    "\n",
    "    set_seed(42)  # Ensure reproducibility\n",
    "    print(f\"Training model: {model.__class__.__name__}\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    tqdm_train_loader = tqdm.tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    tqdm_val_loader = tqdm.tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for signals, labels in tqdm_train_loader:\n",
    "            signals, labels = signals.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(signals.unsqueeze(1))  # Add channel dimension\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(tqdm_train_loader)\n",
    "        train_accuracy = correct / total\n",
    "\n",
    "        # ------------------- Validation -------------------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for signals, labels in tqdm_val_loader:\n",
    "                signals, labels = signals.to(device), labels.to(device)\n",
    "                outputs = model(signals.unsqueeze(1))\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(tqdm_val_loader)\n",
    "        val_accuracy = val_correct / val_total\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{epochs}], \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n",
    "            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\"\n",
    "        )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# GENERAL MODEL, DOES NOT REQUIRE SVM TRAINING\n",
    "def evaluate_model(model, data_loader, device):\n",
    "\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for signals, labels in tqdm.tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            signals = signals.unsqueeze(1).to(device)\n",
    "            predictions = model.predict(signals)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    return accuracy, all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc5084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to keep the training function in a managable state, not a necessary functionality\n",
    "def extract_features_from_loader(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for signals, labels in tqdm.tqdm(data_loader, desc=\"Extracting features\"):\n",
    "            signals = signals.unsqueeze(1).to(device) \n",
    "            features = model.cnn_feature_extractor(signals)\n",
    "\n",
    "            all_features.append(features.cpu().numpy())\n",
    "            all_labels.append(labels.numpy())\n",
    "\n",
    "    all_features = np.concatenate(all_features, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    return all_features, all_labels\n",
    "\n",
    "\n",
    "def train_cnn_svm_model(\n",
    "    model: CNNwithSVM, train_loader, val_loader, epochs=10, lr=0.001\n",
    "):\n",
    "    set_seed(42) \n",
    "    print(f\"Training CNN with SVM: {model.__class__.__name__}\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "\n",
    "    input_channels = model.cnn_feature_extractor.input_channels\n",
    "    input_length = model.cnn_feature_extractor.input_length\n",
    "    feature_size = model.cnn_feature_extractor.feature_size\n",
    "\n",
    "    fc_classifier_model = SimpleCNN(\n",
    "        input_channels=input_channels,\n",
    "        feature_size=feature_size,\n",
    "        input_length=input_length,\n",
    "    )\n",
    "    fc_classifier_model.to(device)\n",
    "\n",
    "    trained_cnn = train_model(\n",
    "        fc_classifier_model, train_loader, val_loader, epochs=epochs, lr=lr\n",
    "    )\n",
    "\n",
    "    model.cnn_feature_extractor = trained_cnn.cnn_feature_extractor\n",
    "    model.to(device)\n",
    "\n",
    "    train_features, train_labels = extract_features_from_loader(\n",
    "        model, train_loader, device\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Training SVM on {len(train_features)} samples with {train_features.shape[1]} features\"\n",
    "    )\n",
    "\n",
    "    model.svm.fit(train_features, train_labels)\n",
    "    model.is_svm_trained = True\n",
    "    print(\"SVM trained successfully!\")\n",
    "\n",
    "    # ------------------- Validation -------------------\n",
    "    val_features, val_labels = extract_features_from_loader(model, val_loader, device)\n",
    "\n",
    "    svm_predictions = model.svm.predict(val_features)\n",
    "    svm_accuracy = accuracy_score(val_labels, svm_predictions)\n",
    "\n",
    "    print(f\"SVM Validation Accuracy: {svm_accuracy:.4f}\")\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(val_labels, svm_predictions))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df59aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate actual input length after transformation\n",
    "sample_signal = pad_or_trim(train_df.iloc[0][\"signal\"], target_length=9000)\n",
    "sample_signal = fourier_transform(sample_signal)\n",
    "print(len(sample_signal))  # 143 for wavelet "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2357216e",
   "metadata": {},
   "source": [
    "# Grid Search for Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_space = {\n",
    "    \"model\": [SimpleCNN, CNNwithSVM],\n",
    "    \"signal_transform\": [None, \"wavelet\", \"fourier\"],\n",
    "    \"augmentation\": [\n",
    "        \"all\",\n",
    "        \"shift_only\",\n",
    "        \"noise_only\",\n",
    "        \"warp_only\",\n",
    "        \"scale_only\",\n",
    "        None,\n",
    "    ],\n",
    "    \"mother_wavelet\": [\"db2\", \"haar\"],  # For wavelet transform, TODO\n",
    "    \"levels\": [6, 4],  # For wavelet transform, TODO\n",
    "}\n",
    "\n",
    "results = []\n",
    "print(\"Starting tests with different configurations...\")\n",
    "\n",
    "for model in test_space[\"model\"]:\n",
    "    for signal_transform in test_space[\"signal_transform\"]:\n",
    "        for augmentation in test_space[\"augmentation\"]:\n",
    "            print(f\"Testing {model.__name__} with {signal_transform} and {augmentation}\")\n",
    "            input_length = expected_lengths[signal_transform]\n",
    "            model_instance = model(input_channels=1, feature_size=50, num_classes=5, input_length=input_length)\n",
    "            model_instance = model_instance.to(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "\n",
    "            train_set = ECGDataset(train_df, signal_transform=signal_transform, augmentation=augmentation)\n",
    "            val_set = ECGDataset(val_df, signal_transform=signal_transform)\n",
    "\n",
    "            train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, generator=torch.Generator().manual_seed(42))\n",
    "            val_loader = DataLoader(val_set, batch_size=BATCH_SIZE)\n",
    "\n",
    "            trained_model = train_cnn_svm_model(model_instance, train_loader, val_loader, epochs=1, lr=0.001) if model == CNNwithSVM else train_model(model_instance, train_loader, val_loader, epochs=1, lr=0.001)\n",
    "\n",
    "            accuracy, _, _ = evaluate_model(\n",
    "                trained_model, val_loader, \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "            )\n",
    "            print(f\"Validation Accuracy of {model.__name__} with {signal_transform} and {augmentation}: {accuracy:.4f}\\n\")\n",
    "            results.append({\n",
    "                \"model\": model.__name__,\n",
    "                \"signal_transform\": signal_transform,\n",
    "                \"augmentation\": augmentation,\n",
    "                \"accuracy\": accuracy,\n",
    "            })\n",
    "            del trained_model, train_loader, val_loader, train_set, val_set\n",
    "            torch.cuda.empty_cache()  # Clear GPU memory after each test\n",
    "\n",
    "print(\"All tests completed.\")\n",
    "print(\"Best result found:\")\n",
    "best_result = max(results, key=lambda x: x[\"accuracy\"])\n",
    "print(f\"Model: {best_result['model']}, Signal Transform: {best_result['signal_transform']}, Augmentation: {best_result['augmentation']}, Accuracy: {best_result['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bacff6",
   "metadata": {},
   "source": [
    "##### Scrapped ideas\n",
    "- mixture of experts with 3 modalities (time domain, frequency domain, wavelet domain)-- could be out of scope\n",
    "- CWT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
