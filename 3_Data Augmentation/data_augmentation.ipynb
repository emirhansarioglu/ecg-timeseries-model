{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1713c311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (5252, 4)\n",
      "Validation DataFrame shape: (927, 4)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "FILE_DIR = Path().resolve().parent\n",
    "DATA_DIR = FILE_DIR / \"2_models\"\n",
    "\n",
    "\n",
    "train_df = pd.read_pickle(f\"{DATA_DIR}/train_df.pkl\")\n",
    "val_df = pd.read_pickle(f\"{DATA_DIR}/val_df.pkl\")\n",
    "\n",
    "print(f\"Train DataFrame shape: {train_df.shape}\")\n",
    "print(f\"Validation DataFrame shape: {val_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3085bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7268f3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>label</th>\n",
       "      <th>signal</th>\n",
       "      <th>rr_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18000</td>\n",
       "      <td>2</td>\n",
       "      <td>[-446, -541, -637, -733, -819, -858, -867, -87...</td>\n",
       "      <td>182.922570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1255, -1488, -1745, -2015, -2253, -2374, -23...</td>\n",
       "      <td>123.855300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>[156, 189, 223, 255, 291, 330, 362, 380, 390, ...</td>\n",
       "      <td>32.132097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-22, -27, -33, -38, -40, -39, -36, -30, -23, ...</td>\n",
       "      <td>145.925780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>[291, 345, 405, 465, 510, 527, 516, 509, 507, ...</td>\n",
       "      <td>16.995531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length  label                                             signal  \\\n",
       "1   18000      2  [-446, -541, -637, -733, -819, -858, -867, -87...   \n",
       "3    9000      0  [-1255, -1488, -1745, -2015, -2253, -2374, -23...   \n",
       "4    9000      0  [156, 189, 223, 255, 291, 330, 362, 380, 390, ...   \n",
       "5    9000      1  [-22, -27, -33, -38, -40, -39, -36, -30, -23, ...   \n",
       "6    9000      0  [291, 345, 405, 465, 510, 527, 516, 509, 507, ...   \n",
       "\n",
       "       rr_std  \n",
       "1  182.922570  \n",
       "3  123.855300  \n",
       "4   32.132097  \n",
       "5  145.925780  \n",
       "6   16.995531  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6070a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts in filtered DataFrame:\n",
      "label\n",
      "0    1446\n",
      "2     962\n",
      "1     407\n",
      "3     179\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>label</th>\n",
       "      <th>signal</th>\n",
       "      <th>rr_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18000</td>\n",
       "      <td>2</td>\n",
       "      <td>[-446, -541, -637, -733, -819, -858, -867, -87...</td>\n",
       "      <td>182.922570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1255, -1488, -1745, -2015, -2253, -2374, -23...</td>\n",
       "      <td>123.855300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-22, -27, -33, -38, -40, -39, -36, -30, -23, ...</td>\n",
       "      <td>145.925780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>[43, 56, 63, 69, 73, 78, 82, 85, 88, 91, 93, 9...</td>\n",
       "      <td>154.062144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3178</td>\n",
       "      <td>1</td>\n",
       "      <td>[107, 128, 155, 166, 173, 179, 183, 187, 190, ...</td>\n",
       "      <td>101.254042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>9000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-12, -14, -16, -17, -19, -21, -22, -35, -68, ...</td>\n",
       "      <td>133.101465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>[546, 588, 632, 679, 696, 673, 605, 536, 512, ...</td>\n",
       "      <td>223.473714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>[503, 600, 695, 789, 873, 915, 911, 891, 883, ...</td>\n",
       "      <td>115.361407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177</th>\n",
       "      <td>9000</td>\n",
       "      <td>2</td>\n",
       "      <td>[271, 469, 690, 862, 932, 875, 707, 456, 177, ...</td>\n",
       "      <td>112.098171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>18000</td>\n",
       "      <td>2</td>\n",
       "      <td>[-114, -140, -157, -163, -168, -174, -160, -14...</td>\n",
       "      <td>142.587553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2994 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  label                                             signal  \\\n",
       "1      18000      2  [-446, -541, -637, -733, -819, -858, -867, -87...   \n",
       "3       9000      0  [-1255, -1488, -1745, -2015, -2253, -2374, -23...   \n",
       "5       9000      1  [-22, -27, -33, -38, -40, -39, -36, -30, -23, ...   \n",
       "10      9000      0  [43, 56, 63, 69, 73, 78, 82, 85, 88, 91, 93, 9...   \n",
       "15      3178      1  [107, 128, 155, 166, 173, 179, 183, 187, 190, ...   \n",
       "...      ...    ...                                                ...   \n",
       "6173    9000      1  [-12, -14, -16, -17, -19, -21, -22, -35, -68, ...   \n",
       "6174    9000      0  [546, 588, 632, 679, 696, 673, 605, 536, 512, ...   \n",
       "6175    9000      0  [503, 600, 695, 789, 873, 915, 911, 891, 883, ...   \n",
       "6177    9000      2  [271, 469, 690, 862, 932, 875, 707, 456, 177, ...   \n",
       "6178   18000      2  [-114, -140, -157, -163, -168, -174, -160, -14...   \n",
       "\n",
       "          rr_std  \n",
       "1     182.922570  \n",
       "3     123.855300  \n",
       "5     145.925780  \n",
       "10    154.062144  \n",
       "15    101.254042  \n",
       "...          ...  \n",
       "6173  133.101465  \n",
       "6174  223.473714  \n",
       "6175  115.361407  \n",
       "6177  112.098171  \n",
       "6178  142.587553  \n",
       "\n",
       "[2994 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out rows with rr_std greater than 100\n",
    "filtered_df = train_df[train_df[\"rr_std\"] > 100]\n",
    "#get total labels for each class\n",
    "label_counts = filtered_df[\"label\"].value_counts()\n",
    "print(\"Label counts in filtered DataFrame:\")\n",
    "print(label_counts)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dcda2c",
   "metadata": {},
   "source": [
    "# MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a2538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "set_seed(42)\n",
    "\n",
    "# STDFT function to compute the Short-Time Fourier Transform (STFT) for a batch of signals\n",
    "# It convert into time -frequency representation\n",
    "# n_fft: size of the FFT window(300 hz is the sampling rate, so 256 is a good choice to capture more than 1 heart beat)\n",
    "# hop_length: number of samples between successive frames (128 is a good choice since every window will overlap by 50%)\n",
    "def compute_stft_batch(x, n_fft=256, hop_length=128):\n",
    "    stft = torch.stft(\n",
    "        x, n_fft=n_fft, hop_length=hop_length,\n",
    "        return_complex=True\n",
    "    )\n",
    "    return torch.abs(stft)  \n",
    "\n",
    "# 2. Model\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self,hidden_size=128, dropout_rate=0.0):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "\n",
    "        # RNN\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=32 * 32, # out_channels * frequency_bins // 2 // 2 (due to max pooling) ()\n",
    "            hidden_size= hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Fully connected\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, 4)  # 4 classes: Normal, AF, Other, Noisy\n",
    "\n",
    "    def forward(self, x:torch.Tensor)-> torch.Tensor:\n",
    "        # x: (batch_size, signal_length)\n",
    "        #print(\"Input:\", x.shape)\n",
    "        x = compute_stft_batch(x)  # STFT â†’ (batch, freq, time)\n",
    "        #print(\"After STFT:\", x.shape)\n",
    "        x = torch.log1p(x)  # logarithmic scaling\n",
    "        #print(\"After log1p:\", x.shape)\n",
    "        \n",
    "\n",
    "        x = x.unsqueeze(1)  # CNN input shape: (batch, channel, freq, time)\n",
    "        #print(\"After Unsqueeze:\", x.shape)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        #print(\"After conv2:\", x.shape)\n",
    "\n",
    "        # Flatten the output for RNN input\n",
    "        b, c, f, t = x.shape  # batch, channel, freq, time\n",
    "        x = x.view(b, c * f, t)  # (batch, features, time)\n",
    "        #print(\"After view:\", x.shape)\n",
    "        x = x.permute(0, 2, 1)   # (batch, time, features)\n",
    "        #print(\"After permute:\", x.shape)\n",
    "\n",
    "        # RNN\n",
    "        output, h_n = self.rnn(x)\n",
    "        #print(\"After RNN output:\", output.shape)\n",
    "        x = self.dropout(h_n[-1])\n",
    "        x = self.fc(x)  # use the last hidden state for classification\n",
    "        #print(\"Final output:\", x.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c272a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e233f",
   "metadata": {},
   "source": [
    "# Augmentation\n",
    "Number and type of augmentation specific to each class\n",
    "\n",
    "Only 1 random augmentation per signal\n",
    "\n",
    "Filtering based on the rr_std limit (only clean signals are augmented)\n",
    "\n",
    "Noisy class is excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4883ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "def pad_or_trim(signal, target_length=9000):\n",
    "    current_length = len(signal)\n",
    "\n",
    "    if current_length < target_length:\n",
    "        # Pad with zeros at the end\n",
    "        padding = target_length - current_length\n",
    "        signal = np.pad(signal, (0, padding), 'constant')\n",
    "    elif current_length > target_length:\n",
    "        # Trim from center\n",
    "        start = (current_length - target_length) // 2\n",
    "        signal = signal[start : start + target_length]\n",
    "\n",
    "    return signal\n",
    "\n",
    "def time_shift(signal, shift_max=100):\n",
    "    shift = np.random.randint(-shift_max, shift_max)\n",
    "    return np.roll(signal, shift)\n",
    "\n",
    "\n",
    "def scale_amplitude(signal, scale_range=(0.95, 1.05)):\n",
    "    scale = np.random.uniform(*scale_range)\n",
    "    return signal * scale\n",
    "\n",
    "def add_noise(signal, noise_level=0.001):\n",
    "    noise = np.random.normal(0, noise_level * np.std(signal), size=signal.shape)\n",
    "    return signal + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4cf54c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "# Augmentation strategy\n",
    "augment_strategy = {\n",
    "    0: 1,  # Normal\n",
    "    1: 5,  # AF\n",
    "    2: 2,  # Other\n",
    "    3: 0   # Noisy\n",
    "}\n",
    "\n",
    "# Possible augmentation types for each class\n",
    "augment_types_per_class = {\n",
    "    0: [\"noise\", \"shift\", \"scale\"],      # Normal\n",
    "    1: [\"shift\", \"scale\"],               # AF (noise yok!)\n",
    "    2: [\"noise\", \"shift\", \"scale\"],      # Other\n",
    "    3: []                                # Noisy (yok)\n",
    "}\n",
    "\n",
    "# Define the rr_std limits for each label for augmentation based ond EDA\n",
    "# 0: Normal, 1: AF, 2: Other, 3: Noisy\n",
    "rr_std_limits = {\n",
    "    0: 110,  \n",
    "    1: 150,  \n",
    "    2: 130,  \n",
    "    3: 0    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f569547d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Augment edilmiÅŸ veri kaydedildi: 9914 Ã¶rnek -> C:\\Users\\emert\\Desktop\\ecg-timeseries-model\\2_models/train_df_final_augmented.pkl\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "augmented_data = []\n",
    "\n",
    "for i, row in train_df.iterrows():\n",
    "    signal = row[\"signal\"]\n",
    "    label = row[\"label\"]\n",
    "    rr_std = row[\"rr_std\"]\n",
    "\n",
    "    # Normalize\n",
    "    signal = pad_or_trim(signal)\n",
    "\n",
    "    # check if augmentation is needed\n",
    "    if rr_std < rr_std_limits[label] and augment_strategy[label] > 0:\n",
    "        for _ in range(augment_strategy[label]):\n",
    "            aug_signal = signal.copy()\n",
    "            aug_signal = np.array(aug_signal)\n",
    "\n",
    "            # choose a random augmentation type for the current label\n",
    "            np.random.seed(42) \n",
    "            aug_type = np.random.choice(augment_types_per_class[label])\n",
    "\n",
    "            if aug_type == \"noise\":\n",
    "                aug_signal = add_noise(aug_signal)\n",
    "            elif aug_type == \"shift\":\n",
    "                aug_signal = time_shift(aug_signal)\n",
    "            elif aug_type == \"scale\":\n",
    "                aug_signal = scale_amplitude(aug_signal)\n",
    "\n",
    "            aug_signal = pad_or_trim(aug_signal)\n",
    "\n",
    "            augmented_data.append({\n",
    "                \"signal\": aug_signal.tolist(),\n",
    "                \"label\": label,\n",
    "                \"length\": 9000,\n",
    "                \"rr_std\": rr_std\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "train_df[\"signal\"] = train_df[\"signal\"].apply(pad_or_trim)\n",
    "train_df[\"length\"] = 9000\n",
    "\n",
    "full_train_df = pd.concat([train_df, pd.DataFrame(augmented_data)], ignore_index=True)\n",
    "\n",
    "output_path = f\"{DATA_DIR}/train_df_final_augmented.pkl\"\n",
    "full_train_df.to_pickle(output_path)\n",
    "print(f\"\\nâœ… Augment edilmiÅŸ veri kaydedildi: {len(full_train_df)} Ã¶rnek -> {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e20031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "from torch.utils.data import DataLoader\n",
    "def train_one_epoch(model:nn.Module, \n",
    "                    dataloader:DataLoader, \n",
    "                    optimizer:torch.optim.Optimizer, \n",
    "                    loss_fn:nn.Module):\n",
    "    \"\"\"\n",
    "    Trains the model for one full epoch.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model (ECGModel).\n",
    "        dataloader: The training DataLoader providing batches.\n",
    "        optimizer: The optimizer (e.g., Adam).\n",
    "        loss_fn: The loss function (e.g., CrossEntropyLoss).\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (average_loss, accuracy) for the epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for signals, labels in dataloader:\n",
    "        signals = signals.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(signals)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * signals.size(0)\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "341ac0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original weights:  [ 0.51124175  1.42853026  0.78958267 12.90885417]\n",
      "Scaled weights:  [0.51980198 0.55533141 0.53058299 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Compute class weights based on the training labels\n",
    "original_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array([0, 1, 2, 3]),\n",
    "    y=full_train_df['label'].values\n",
    ")\n",
    "\n",
    "# Normalize and scale the weights\n",
    "scaled_weights = original_weights / original_weights.max()  # normalize to max=1\n",
    "scaled_weights = 0.5 + (scaled_weights * 0.5)  # shrink range to [0.5, 1.0] for balance\n",
    "\n",
    "weights_tensor = torch.tensor(scaled_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# Weighted loss function\n",
    "loss_fn_weighted = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "print(\"Original weights: \", original_weights)\n",
    "print(\"Scaled weights: \", scaled_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04aacc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, precision_score, recall_score,accuracy_score\n",
    "\n",
    "def evaluate_with_metrics(model:nn.Module, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for signals, labels in dataloader:\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(signals)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=[0, 1, 2, 3])\n",
    "    report = classification_report(\n",
    "    all_labels, all_preds,\n",
    "    labels=[0, 1, 2, 3],\n",
    "    target_names=['Normal', 'AF', 'Other', 'Noisy'],\n",
    "    zero_division=0  # uyarÄ± vermesin\n",
    ")\n",
    "\n",
    "    return avg_loss, accuracy, f1, precision, cm, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09c404b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, df, target_length=9000):\n",
    "        self.df = df\n",
    "        self.target_length = target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Signal processing\n",
    "        # Pad or trim the signal to the target length\n",
    "        signal = pad_or_trim(row['signal'], self.target_length)\n",
    "        signal = torch.tensor(signal, dtype=torch.float32)\n",
    "        label = int(row['label']) \n",
    "\n",
    "        return signal, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e3bd22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Full train DataFrame shape: (9914, 4)\n",
      " Validation DataFrame shape: (927, 4)\n",
      "label\n",
      "0    4848\n",
      "1    1735\n",
      "2    3139\n",
      "3     192\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\" Full train DataFrame shape:\", full_train_df.shape)\n",
    "print(\" Validation DataFrame shape:\", val_df.shape)\n",
    "print(full_train_df[\"label\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fa95dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "train_dataset = ECGDataset(full_train_df)\n",
    "val_dataset = ECGDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, generator=torch.Generator().manual_seed(42))\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "model = ECGModel(hidden_size=256, dropout_rate=0.3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0005)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights_tensor.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f41adf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Train Loss: 1.1250 | Train Acc: 0.4815\n",
      "Val   Loss: 0.9671 | Val   Acc: 0.5804\n",
      "Val   F1: 0.2165 | Val Precision: 0.3989\n",
      "----------------------------------------\n",
      "Epoch 2/20\n",
      "Train Loss: 1.0054 | Train Acc: 0.5533\n",
      "Val   Loss: 0.9232 | Val   Acc: 0.5944\n",
      "Val   F1: 0.3577 | Val Precision: 0.3678\n",
      "----------------------------------------\n",
      "Epoch 3/20\n",
      "Train Loss: 0.8545 | Train Acc: 0.6383\n",
      "Val   Loss: 0.8452 | Val   Acc: 0.6408\n",
      "Val   F1: 0.3735 | Val Precision: 0.5221\n",
      "----------------------------------------\n",
      "Epoch 4/20\n",
      "Train Loss: 0.7942 | Train Acc: 0.6597\n",
      "Val   Loss: 0.8941 | Val   Acc: 0.6084\n",
      "Val   F1: 0.4528 | Val Precision: 0.6000\n",
      "----------------------------------------\n",
      "Epoch 5/20\n",
      "Train Loss: 0.7584 | Train Acc: 0.6739\n",
      "Val   Loss: 0.8317 | Val   Acc: 0.6472\n",
      "Val   F1: 0.4648 | Val Precision: 0.5878\n",
      "----------------------------------------\n",
      "Epoch 6/20\n",
      "Train Loss: 0.7344 | Train Acc: 0.6845\n",
      "Val   Loss: 0.8352 | Val   Acc: 0.6365\n",
      "Val   F1: 0.4631 | Val Precision: 0.5191\n",
      "----------------------------------------\n",
      "EarlyStopping Counter: 1 / 5\n",
      "Epoch 7/20\n",
      "Train Loss: 0.7116 | Train Acc: 0.6954\n",
      "Val   Loss: 0.7759 | Val   Acc: 0.6721\n",
      "Val   F1: 0.5156 | Val Precision: 0.6786\n",
      "----------------------------------------\n",
      "Epoch 8/20\n",
      "Train Loss: 0.6780 | Train Acc: 0.7100\n",
      "Val   Loss: 0.8353 | Val   Acc: 0.6602\n",
      "Val   F1: 0.5556 | Val Precision: 0.5653\n",
      "----------------------------------------\n",
      "Epoch 9/20\n",
      "Train Loss: 0.6557 | Train Acc: 0.7175\n",
      "Val   Loss: 0.8103 | Val   Acc: 0.6591\n",
      "Val   F1: 0.5157 | Val Precision: 0.5882\n",
      "----------------------------------------\n",
      "EarlyStopping Counter: 1 / 5\n",
      "Epoch 10/20\n",
      "Train Loss: 0.6306 | Train Acc: 0.7289\n",
      "Val   Loss: 0.8116 | Val   Acc: 0.6742\n",
      "Val   F1: 0.4898 | Val Precision: 0.6593\n",
      "----------------------------------------\n",
      "EarlyStopping Counter: 2 / 5\n",
      "Epoch 11/20\n",
      "Train Loss: 0.6001 | Train Acc: 0.7479\n",
      "Val   Loss: 0.7925 | Val   Acc: 0.6742\n",
      "Val   F1: 0.5806 | Val Precision: 0.5837\n",
      "----------------------------------------\n",
      "Epoch 12/20\n",
      "Train Loss: 0.5662 | Train Acc: 0.7634\n",
      "Val   Loss: 0.8202 | Val   Acc: 0.6764\n",
      "Val   F1: 0.6014 | Val Precision: 0.6346\n",
      "----------------------------------------\n",
      "Epoch 13/20\n",
      "Train Loss: 0.5355 | Train Acc: 0.7742\n",
      "Val   Loss: 0.7655 | Val   Acc: 0.6936\n",
      "Val   F1: 0.5700 | Val Precision: 0.6746\n",
      "----------------------------------------\n",
      "EarlyStopping Counter: 1 / 5\n",
      "Epoch 14/20\n",
      "Train Loss: 0.4927 | Train Acc: 0.7970\n",
      "Val   Loss: 0.8680 | Val   Acc: 0.6483\n",
      "Val   F1: 0.5892 | Val Precision: 0.6281\n",
      "----------------------------------------\n",
      "EarlyStopping Counter: 2 / 5\n",
      "Epoch 15/20\n",
      "Train Loss: 0.4544 | Train Acc: 0.8163\n",
      "Val   Loss: 0.8813 | Val   Acc: 0.6591\n",
      "Val   F1: 0.5778 | Val Precision: 0.6429\n",
      "----------------------------------------\n",
      "EarlyStopping Counter: 3 / 5\n",
      "Epoch 16/20\n",
      "Train Loss: 0.4038 | Train Acc: 0.8400\n",
      "Val   Loss: 0.8521 | Val   Acc: 0.6818\n",
      "Val   F1: 0.6029 | Val Precision: 0.6012\n",
      "----------------------------------------\n",
      "Epoch 17/20\n",
      "Train Loss: 0.3380 | Train Acc: 0.8728\n",
      "Val   Loss: 0.9739 | Val   Acc: 0.6980\n",
      "Val   F1: 0.6195 | Val Precision: 0.6925\n",
      "----------------------------------------\n",
      "Epoch 18/20\n",
      "Train Loss: 0.2747 | Train Acc: 0.9000\n",
      "Val   Loss: 1.0915 | Val   Acc: 0.6494\n",
      "Val   F1: 0.5735 | Val Precision: 0.6147\n",
      "----------------------------------------\n",
      "EarlyStopping Counter: 1 / 5\n",
      "Epoch 19/20\n",
      "Train Loss: 0.2361 | Train Acc: 0.9175\n",
      "Val   Loss: 1.0590 | Val   Acc: 0.6559\n",
      "Val   F1: 0.6060 | Val Precision: 0.5998\n",
      "----------------------------------------\n",
      "EarlyStopping Counter: 2 / 5\n",
      "Epoch 20/20\n",
      "Train Loss: 0.1767 | Train Acc: 0.9394\n",
      "Val   Loss: 1.1749 | Val   Acc: 0.6764\n",
      "Val   F1: 0.5497 | Val Precision: 0.6109\n",
      "----------------------------------------\n",
      "EarlyStopping Counter: 3 / 5\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "num_epochs = 20\n",
    "best_val_f1 = 0\n",
    "patience = 5\n",
    "counter = 0\n",
    "best_model_state = None\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, loss_fn)\n",
    "    val_loss, val_acc, val_f1, val_precision, cm, val_report = evaluate_with_metrics(model, val_loader, loss_fn, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n",
    "    print(f\"Val   F1: {val_f1:.4f} | Val Precision: {val_precision:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        best_model_state =  copy.deepcopy(model.state_dict())\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"EarlyStopping Counter: {counter} / {patience}\")\n",
    "        if counter >= patience:\n",
    "            print(\"ðŸ”´ Early stopping triggered!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc98b3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef741203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 Score: 0.6195\n",
      "Confusion Matrix:\n",
      " [[464   3  76   1]\n",
      " [ 23  38  21   2]\n",
      " [121  15 127   1]\n",
      " [ 10   3   4  18]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.75      0.85      0.80       544\n",
      "          AF       0.64      0.45      0.53        84\n",
      "       Other       0.56      0.48      0.52       264\n",
      "       Noisy       0.82      0.51      0.63        35\n",
      "\n",
      "    accuracy                           0.70       927\n",
      "   macro avg       0.69      0.58      0.62       927\n",
      "weighted avg       0.69      0.70      0.69       927\n",
      "\n",
      "vall acc: 0.697950377562028\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc, val_f1, val_precision, val_cm, val_report = evaluate_with_metrics(model, val_loader, loss_fn, device)\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", val_cm)\n",
    "print(\"Classification Report:\\n\", val_report)\n",
    "print(\"vall acc:\", val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
