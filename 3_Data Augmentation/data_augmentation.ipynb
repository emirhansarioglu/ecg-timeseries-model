{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1713c311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (5252, 4)\n",
      "Validation DataFrame shape: (927, 4)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "FILE_DIR = Path().resolve().parent\n",
    "DATA_DIR = FILE_DIR / \"2_models\"\n",
    "\n",
    "\n",
    "train_df = pd.read_pickle(f\"{DATA_DIR}/train_df.pkl\")\n",
    "val_df = pd.read_pickle(f\"{DATA_DIR}/val_df.pkl\")\n",
    "\n",
    "print(f\"Train DataFrame shape: {train_df.shape}\")\n",
    "print(f\"Validation DataFrame shape: {val_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da3085bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7268f3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>label</th>\n",
       "      <th>signal</th>\n",
       "      <th>rr_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18000</td>\n",
       "      <td>2</td>\n",
       "      <td>[-446, -541, -637, -733, -819, -858, -867, -87...</td>\n",
       "      <td>182.922570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1255, -1488, -1745, -2015, -2253, -2374, -23...</td>\n",
       "      <td>123.855300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>[156, 189, 223, 255, 291, 330, 362, 380, 390, ...</td>\n",
       "      <td>32.132097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-22, -27, -33, -38, -40, -39, -36, -30, -23, ...</td>\n",
       "      <td>145.925780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>[291, 345, 405, 465, 510, 527, 516, 509, 507, ...</td>\n",
       "      <td>16.995531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length  label                                             signal  \\\n",
       "1   18000      2  [-446, -541, -637, -733, -819, -858, -867, -87...   \n",
       "3    9000      0  [-1255, -1488, -1745, -2015, -2253, -2374, -23...   \n",
       "4    9000      0  [156, 189, 223, 255, 291, 330, 362, 380, 390, ...   \n",
       "5    9000      1  [-22, -27, -33, -38, -40, -39, -36, -30, -23, ...   \n",
       "6    9000      0  [291, 345, 405, 465, 510, 527, 516, 509, 507, ...   \n",
       "\n",
       "       rr_std  \n",
       "1  182.922570  \n",
       "3  123.855300  \n",
       "4   32.132097  \n",
       "5  145.925780  \n",
       "6   16.995531  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6070a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts in filtered DataFrame:\n",
      "label\n",
      "0    1446\n",
      "2     962\n",
      "1     407\n",
      "3     179\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>label</th>\n",
       "      <th>signal</th>\n",
       "      <th>rr_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18000</td>\n",
       "      <td>2</td>\n",
       "      <td>[-446, -541, -637, -733, -819, -858, -867, -87...</td>\n",
       "      <td>182.922570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1255, -1488, -1745, -2015, -2253, -2374, -23...</td>\n",
       "      <td>123.855300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-22, -27, -33, -38, -40, -39, -36, -30, -23, ...</td>\n",
       "      <td>145.925780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>[43, 56, 63, 69, 73, 78, 82, 85, 88, 91, 93, 9...</td>\n",
       "      <td>154.062144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3178</td>\n",
       "      <td>1</td>\n",
       "      <td>[107, 128, 155, 166, 173, 179, 183, 187, 190, ...</td>\n",
       "      <td>101.254042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>9000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-12, -14, -16, -17, -19, -21, -22, -35, -68, ...</td>\n",
       "      <td>133.101465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>[546, 588, 632, 679, 696, 673, 605, 536, 512, ...</td>\n",
       "      <td>223.473714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>[503, 600, 695, 789, 873, 915, 911, 891, 883, ...</td>\n",
       "      <td>115.361407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177</th>\n",
       "      <td>9000</td>\n",
       "      <td>2</td>\n",
       "      <td>[271, 469, 690, 862, 932, 875, 707, 456, 177, ...</td>\n",
       "      <td>112.098171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>18000</td>\n",
       "      <td>2</td>\n",
       "      <td>[-114, -140, -157, -163, -168, -174, -160, -14...</td>\n",
       "      <td>142.587553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2994 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  label                                             signal  \\\n",
       "1      18000      2  [-446, -541, -637, -733, -819, -858, -867, -87...   \n",
       "3       9000      0  [-1255, -1488, -1745, -2015, -2253, -2374, -23...   \n",
       "5       9000      1  [-22, -27, -33, -38, -40, -39, -36, -30, -23, ...   \n",
       "10      9000      0  [43, 56, 63, 69, 73, 78, 82, 85, 88, 91, 93, 9...   \n",
       "15      3178      1  [107, 128, 155, 166, 173, 179, 183, 187, 190, ...   \n",
       "...      ...    ...                                                ...   \n",
       "6173    9000      1  [-12, -14, -16, -17, -19, -21, -22, -35, -68, ...   \n",
       "6174    9000      0  [546, 588, 632, 679, 696, 673, 605, 536, 512, ...   \n",
       "6175    9000      0  [503, 600, 695, 789, 873, 915, 911, 891, 883, ...   \n",
       "6177    9000      2  [271, 469, 690, 862, 932, 875, 707, 456, 177, ...   \n",
       "6178   18000      2  [-114, -140, -157, -163, -168, -174, -160, -14...   \n",
       "\n",
       "          rr_std  \n",
       "1     182.922570  \n",
       "3     123.855300  \n",
       "5     145.925780  \n",
       "10    154.062144  \n",
       "15    101.254042  \n",
       "...          ...  \n",
       "6173  133.101465  \n",
       "6174  223.473714  \n",
       "6175  115.361407  \n",
       "6177  112.098171  \n",
       "6178  142.587553  \n",
       "\n",
       "[2994 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out rows with rr_std greater than 100\n",
    "filtered_df = train_df[train_df[\"rr_std\"] > 100]\n",
    "#get total labels for each class\n",
    "label_counts = filtered_df[\"label\"].value_counts()\n",
    "print(\"Label counts in filtered DataFrame:\")\n",
    "print(label_counts)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dcda2c",
   "metadata": {},
   "source": [
    "# MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# STDFT function to compute the Short-Time Fourier Transform (STFT) for a batch of signals\n",
    "# It convert into time -frequency representation\n",
    "# n_fft: size of the FFT window(300 hz is the sampling rate, so 256 is a good choice to capture more than 1 heart beat)\n",
    "# hop_length: number of samples between successive frames (128 is a good choice since every window will overlap by 50%)\n",
    "def compute_stft_batch(x, n_fft=256, hop_length=128):\n",
    "    stft = torch.stft(\n",
    "        x, n_fft=n_fft, hop_length=hop_length,\n",
    "        return_complex=True\n",
    "    )\n",
    "    return torch.abs(stft)  \n",
    "\n",
    "# 2. Model\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self,hidden_size=128, dropout_rate=0.0):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "\n",
    "        # RNN\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=32 * 32, # out_channels * frequency_bins // 2 // 2 (due to max pooling) ()\n",
    "            hidden_size= hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Fully connected\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, 4)  # 4 classes: Normal, AF, Other, Noisy\n",
    "\n",
    "    def forward(self, x:torch.Tensor)-> torch.Tensor:\n",
    "        # x: (batch_size, signal_length)\n",
    "        #print(\"Input:\", x.shape)\n",
    "        x = compute_stft_batch(x)  # STFT â†’ (batch, freq, time)\n",
    "        #print(\"After STFT:\", x.shape)\n",
    "        x = torch.log1p(x)  # logarithmic scaling\n",
    "        #print(\"After log1p:\", x.shape)\n",
    "        \n",
    "\n",
    "        x = x.unsqueeze(1)  # CNN input shape: (batch, channel, freq, time)\n",
    "        #print(\"After Unsqueeze:\", x.shape)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        #print(\"After conv2:\", x.shape)\n",
    "\n",
    "        # Flatten the output for RNN input\n",
    "        b, c, f, t = x.shape  # batch, channel, freq, time\n",
    "        x = x.view(b, c * f, t)  # (batch, features, time)\n",
    "        #print(\"After view:\", x.shape)\n",
    "        x = x.permute(0, 2, 1)   # (batch, time, features)\n",
    "        #print(\"After permute:\", x.shape)\n",
    "\n",
    "        # RNN\n",
    "        output, h_n = self.rnn(x)\n",
    "        #print(\"After RNN output:\", output.shape)\n",
    "        x = self.dropout(h_n[-1])\n",
    "        x = self.fc(x)  # use the last hidden state for classification\n",
    "        #print(\"Final output:\", x.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c272a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e233f",
   "metadata": {},
   "source": [
    "# Augmentation\n",
    "Number and type of augmentation specific to each class\n",
    "\n",
    "Only 1 random augmentation per signal\n",
    "\n",
    "Filtering based on the rr_std limit (only clean signals are augmented)\n",
    "\n",
    "Noisy class is excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4883ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_trim(signal, target_length=9000):\n",
    "    current_length = len(signal)\n",
    "\n",
    "    if current_length < target_length:\n",
    "        # Pad with zeros at the end\n",
    "        padding = target_length - current_length\n",
    "        signal = np.pad(signal, (0, padding), 'constant')\n",
    "    elif current_length > target_length:\n",
    "        # Trim from center\n",
    "        start = (current_length - target_length) // 2\n",
    "        signal = signal[start : start + target_length]\n",
    "\n",
    "    return signal\n",
    "\n",
    "def time_shift(signal, shift_max=100):\n",
    "    shift = np.random.randint(-shift_max, shift_max)\n",
    "    return np.roll(signal, shift)\n",
    "\n",
    "\n",
    "def scale_amplitude(signal, scale_range=(0.95, 1.05)):\n",
    "    scale = np.random.uniform(*scale_range)\n",
    "    return signal * scale\n",
    "\n",
    "def add_noise(signal, noise_level=0.001):\n",
    "    noise = np.random.normal(0, noise_level * np.std(signal), size=signal.shape)\n",
    "    return signal + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4cf54c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation strategy\n",
    "augment_strategy = {\n",
    "    0: 1,  # Normal\n",
    "    1: 5,  # AF\n",
    "    2: 2,  # Other\n",
    "    3: 0   # Noisy\n",
    "}\n",
    "\n",
    "# Possible augmentation types for each class\n",
    "augment_types_per_class = {\n",
    "    0: [\"noise\", \"shift\", \"scale\"],      # Normal\n",
    "    1: [\"shift\", \"scale\"],               # AF (noise yok!)\n",
    "    2: [\"noise\", \"shift\", \"scale\"],      # Other\n",
    "    3: []                                # Noisy (yok)\n",
    "}\n",
    "\n",
    "# Define the rr_std limits for each label for augmentation based ond EDA\n",
    "# 0: Normal, 1: AF, 2: Other, 3: Noisy\n",
    "rr_std_limits = {\n",
    "    0: 110,  \n",
    "    1: 150,  \n",
    "    2: 130,  \n",
    "    3: 0    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f569547d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Augment edilmiÅŸ veri kaydedildi: 9914 Ã¶rnek -> C:\\Users\\emert\\Desktop\\ecg-timeseries-model\\2_models/train_df_final_augmented.pkl\n"
     ]
    }
   ],
   "source": [
    "augmented_data = []\n",
    "\n",
    "for i, row in train_df.iterrows():\n",
    "    signal = row[\"signal\"]\n",
    "    label = row[\"label\"]\n",
    "    rr_std = row[\"rr_std\"]\n",
    "\n",
    "    # Normalize\n",
    "    signal = pad_or_trim(signal)\n",
    "\n",
    "    # check if augmentation is needed\n",
    "    if rr_std < rr_std_limits[label] and augment_strategy[label] > 0:\n",
    "        for _ in range(augment_strategy[label]):\n",
    "            aug_signal = signal.copy()\n",
    "            aug_signal = np.array(aug_signal)\n",
    "\n",
    "            # choose a random augmentation type for the current label\n",
    "            np.random.seed(42) \n",
    "            aug_type = np.random.choice(augment_types_per_class[label])\n",
    "\n",
    "            if aug_type == \"noise\":\n",
    "                aug_signal = add_noise(aug_signal)\n",
    "            elif aug_type == \"shift\":\n",
    "                aug_signal = time_shift(aug_signal)\n",
    "            elif aug_type == \"scale\":\n",
    "                aug_signal = scale_amplitude(aug_signal)\n",
    "\n",
    "            aug_signal = pad_or_trim(aug_signal)\n",
    "\n",
    "            augmented_data.append({\n",
    "                \"signal\": aug_signal.tolist(),\n",
    "                \"label\": label,\n",
    "                \"length\": 9000,\n",
    "                \"rr_std\": rr_std\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "train_df[\"signal\"] = train_df[\"signal\"].apply(pad_or_trim)\n",
    "train_df[\"length\"] = 9000\n",
    "\n",
    "full_train_df = pd.concat([train_df, pd.DataFrame(augmented_data)], ignore_index=True)\n",
    "\n",
    "output_path = f\"{DATA_DIR}/train_df_final_augmented.pkl\"\n",
    "full_train_df.to_pickle(output_path)\n",
    "print(f\"\\nâœ… Augment edilmiÅŸ veri kaydedildi: {len(full_train_df)} Ã¶rnek -> {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e20031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "def train_one_epoch(model:nn.Module, \n",
    "                    dataloader:torch.utils.data.DataLoader, \n",
    "                    optimizer:torch.optim.Optimizer, \n",
    "                    loss_fn:nn.Module):\n",
    "    \"\"\"\n",
    "    Trains the model for one full epoch.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model (ECGModel).\n",
    "        dataloader: The training DataLoader providing batches.\n",
    "        optimizer: The optimizer (e.g., Adam).\n",
    "        loss_fn: The loss function (e.g., CrossEntropyLoss).\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (average_loss, accuracy) for the epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for signals, labels in dataloader:\n",
    "        signals = signals.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(signals)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * signals.size(0)\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ac0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original weights:  [ 0.51124175  1.42853026  0.78958267 12.90885417]\n",
      "Scaled weights:  [0.51980198 0.55533141 0.53058299 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "\n",
    "# Compute class weights based on the training labels\n",
    "original_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array([0, 1, 2, 3]),\n",
    "    y=full_train_df['label'].values\n",
    ")\n",
    "\n",
    "# Normalize and scale the weights\n",
    "scaled_weights = original_weights / original_weights.max()  # normalize to max=1\n",
    "scaled_weights = 0.5 + (scaled_weights * 0.5)  # shrink range to [0.5, 1.0] for balance\n",
    "\n",
    "weights_tensor = torch.tensor(scaled_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# Weighted loss function\n",
    "loss_fn_weighted = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "print(\"Original weights: \", original_weights)\n",
    "print(\"Scaled weights: \", scaled_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aacc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, precision_score, recall_score,accuracy_score\n",
    "\n",
    "def evaluate_with_metrics(model:nn.Module, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for signals, labels in dataloader:\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(signals)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=[0, 1, 2, 3])\n",
    "    report = classification_report(\n",
    "    all_labels, all_preds,\n",
    "    labels=[0, 1, 2, 3],\n",
    "    target_names=['Normal', 'AF', 'Other', 'Noisy'],\n",
    "    zero_division=0  # uyarÄ± vermesin\n",
    ")\n",
    "\n",
    "    return avg_loss, accuracy, f1, precision, cm, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09c404b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, df, target_length=9000):\n",
    "        self.df = df\n",
    "        self.target_length = target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Signal processing\n",
    "        # Pad or trim the signal to the target length\n",
    "        signal = pad_or_trim(row['signal'], self.target_length)\n",
    "        signal = torch.tensor(signal, dtype=torch.float32)\n",
    "        label = int(row['label']) \n",
    "\n",
    "        return signal, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e3bd22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Full train DataFrame shape: (9914, 4)\n",
      " Validation DataFrame shape: (927, 4)\n",
      "label\n",
      "0    4848\n",
      "1    1735\n",
      "2    3139\n",
      "3     192\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\" Full train DataFrame shape:\", full_train_df.shape)\n",
    "print(\" Validation DataFrame shape:\", val_df.shape)\n",
    "print(full_train_df[\"label\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1fa95dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ECGDataset(full_train_df)\n",
    "val_dataset = ECGDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, generator=torch.Generator().manual_seed(42))\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "model = ECGModel(hidden_size=256, dropout_rate=0.3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0005)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights_tensor.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f41adf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Train Loss: 1.1190 | Train Acc: 0.4831\n",
      "Val   Loss: 0.9569 | Val   Acc: 0.5879\n",
      "Val   F1: 0.2601 | Val Precision: 0.4317\n",
      "----------------------------------------\n",
      "Epoch 2/20\n",
      "Train Loss: 1.0363 | Train Acc: 0.5338\n",
      "Val   Loss: 0.8899 | Val   Acc: 0.6343\n",
      "Val   F1: 0.3396 | Val Precision: 0.4248\n",
      "----------------------------------------\n",
      "Epoch 3/20\n",
      "Train Loss: 0.9817 | Train Acc: 0.5735\n",
      "Val   Loss: 0.9164 | Val   Acc: 0.6192\n",
      "Val   F1: 0.4422 | Val Precision: 0.4611\n",
      "----------------------------------------\n",
      "Epoch 4/20\n",
      "Train Loss: 0.9532 | Train Acc: 0.5835\n",
      "Val   Loss: 1.0475 | Val   Acc: 0.5372\n",
      "Val   F1: 0.4487 | Val Precision: 0.4586\n",
      "----------------------------------------\n",
      "Epoch 5/20\n",
      "Train Loss: 0.9274 | Train Acc: 0.5918\n",
      "Val   Loss: 0.8325 | Val   Acc: 0.6526\n",
      "Val   F1: 0.4583 | Val Precision: 0.5806\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m best_model_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 10\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     val_loss, val_acc, val_f1, val_precision, cm, val_report \u001b[38;5;241m=\u001b[39m evaluate_with_metrics(model, val_loader, loss_fn, device)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[49], line 34\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, dataloader, optimizer, loss_fn)\u001b[0m\n\u001b[0;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 34\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     37\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m signals\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\emert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\emert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "num_epochs = 20\n",
    "best_val_f1 = 0\n",
    "patience = 5\n",
    "counter = 0\n",
    "best_model_state = None\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, loss_fn)\n",
    "    val_loss, val_acc, val_f1, val_precision, cm, val_report = evaluate_with_metrics(model, val_loader, loss_fn, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n",
    "    print(f\"Val   F1: {val_f1:.4f} | Val Precision: {val_precision:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        best_model_state =  copy.deepcopy(model.state_dict())\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"EarlyStopping Counter: {counter} / {patience}\")\n",
    "        if counter >= patience:\n",
    "            print(\"ðŸ”´ Early stopping triggered!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc98b3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ECGModel(hidden_size=256, dropout_rate=0.3).to(device)\n",
    "model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef741203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 Score: 0.5770\n",
      "Confusion Matrix:\n",
      " [[402  22 112   8]\n",
      " [ 11  38  30   5]\n",
      " [ 82  29 149   4]\n",
      " [  3   3   8  21]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.81      0.74      0.77       544\n",
      "          AF       0.41      0.45      0.43        84\n",
      "       Other       0.50      0.56      0.53       264\n",
      "       Noisy       0.55      0.60      0.58        35\n",
      "\n",
      "    accuracy                           0.66       927\n",
      "   macro avg       0.57      0.59      0.58       927\n",
      "weighted avg       0.67      0.66      0.66       927\n",
      "\n",
      "vall acc: 0.6580366774541532\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc, val_f1, val_precision, val_cm, val_report = evaluate_with_metrics(model, val_loader, loss_fn, device)\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", val_cm)\n",
    "print(\"Classification Report:\\n\", val_report)\n",
    "print(\"vall acc:\", val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
